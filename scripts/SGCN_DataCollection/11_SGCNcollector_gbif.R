# Name: 
# Purpose: 
# Author: Christopher Tracey
# Created: 2016-08-11
# Updated: 2016-08-17
#
# Updates:
# insert date and info
# * 2016-08-17 - 
#
# To Do List/Future Ideas:
# * 
#---------------------------------------------------------------------------------------------

# clear the environments
rm(list=ls())

# load packages
if (!requireNamespace("here", quietly = TRUE)) install.packages("here")
  require(here)
if (!requireNamespace("rgbif", quietly = TRUE)) install.packages("rgbif")
  require(rgbif)
if (!requireNamespace("purrr", quietly = TRUE)) install.packages("purrr")
require(purrr)
if (!requireNamespace("tidyr", quietly = TRUE)) install.packages("tidyr")
require(tidyr)

source(here::here("scripts","00_PathsAndSettings.r"))

# load the r data file
load(file=updateData)

# read in SGCN data
loadSGCN()

splist <- lu_sgcn$SNAME

# species already in Biotics
splist <- splist[which(!splist %in% SGCN_bioticsCPP)]

# gets the  keys for each species name, based on GBIF
keys <- sapply(splist, function(x) name_backbone(name=x)$speciesKey[1], USE.NAMES=FALSE)

### add some code to put out the list of species not found in GBIF
a1 <- which(sapply(keys,is.null))
missingGBIFsp <- splist[a1]
missingGBIFsp
rm(a1)
cat(length(missingGBIFsp),"of",length(splist), "species were not found in GBIF", "\n", "They are:", paste(missingGBIFsp, collapse=", "))

# gets rid of any null values generated by name_backbone in the case of unmatchable species names
keys1 <- keys[-(which(sapply(keys,is.null),arr.ind=TRUE))] #note: seems to break if there is only one item in the list... use for multiple species!
keys <- keys1
#searches for occurrences
dat <- occ_search(
  taxonKey=keys, 
  limit=10000, # modify if needed, fewer will make testing go faster
  return='data', 
  hasCoordinate=TRUE,
  geometry='POLYGON ((-80.577111647999971 42.018959019000079, -80.583025511999949 39.690462536000041, -77.681987232999973 39.68735201800007, -75.761816590999956 39.690666106000037, -75.678308913999956 39.790810226000076, -75.53064649099997 39.815101786000071, -75.411566911999955 39.776679135000052, -75.101245089999964 39.880029385000057, -75.09383042199994 39.944216030000064, -74.690932882999959 40.133570156000076, -74.690425973999936 40.17528313400004, -74.893196517999968 40.350896889000069, -74.914505704999954 40.415842984000051, -75.012247039999977 40.448477402000037, -75.004556583999943 40.522413349000033, -75.134560399999941 40.623471625000036, -75.136516799999981 40.723392383000032, -75.002409694999983 40.867515299000047, -75.082051382999964 40.971575944000051, -74.830463730999952 41.152763058000062, -74.768212647999974 41.271891205000031, -74.640518995999969 41.358839422000074, -74.709416559999966 41.454495330000043, -74.826329023999961 41.475865789000068, -74.936988959999951 41.521739840000066, -75.018029425999941 41.617276498000081, -75.012709979999954 41.733926517000043, -75.061642930999938 41.85481505100006, -75.218658916999971 41.904656042000056, -75.336705265999967 42.017618624000079, -77.511689405999959 42.017704281000078, -79.721693517999938 42.024739989000068, -79.715980736999938 42.353623043000027, -80.577111647999971 42.018959019000079))', # simplified boundary of Pennsylvania.
  year='1970,2023'
)

dat <-  dat[dat!="no data found, try a different search"] # deletes the items from the list where no occurrences were found. doesn't work for one species
datdf <- lapply(dat, function(x) x[[3]])# selects the $data from each list element

#make the columns all match across the dataframes
#choose which columns you actually care about and will be keeping (these are ragged tables otherwise)
fields <- c('species','scientificName','datasetKey','recordedBy','key','decimalLatitude','decimalLongitude','country','basisOfRecord','coordinateUncertaintyInMeters','coordinateAccuracy','year','month','day')

#not every data frame has every column--this loop adds in the "fields" columns for the dfs that are missing those columns
for (i in 1:length(datdf))    {
  if ((identical(colnames(datdf[[i]]),fields)) == FALSE) {
    nms   = fields
    df =   datdf[[i]]
    aux = colnames(df)
    aux1 = row.names(df)
    
    Missing = setdiff(nms, colnames(df))  
    
    ind = seq(1,length(Missing)) #creating indices 1-5 for loop
    for (j in ind)  {    #loop to add columns with zeros
      df = cbind(df,c(NA))
    }
    colnames(df) = c(aux,Missing)   #updates columns names
    
    df = df[,order(colnames(df))]  #put columns into order
    datdf[[i]] = df              #updates object from list
  } 
}

datdff <- lapply(datdf, '[', fields) #subset out just the focal columns

datdff_df <- dplyr::bind_rows(datdff, .id = "column_label") #turns it into one big dataframe


write.csv(datdff_df, file=paste("gbif_",format(Sys.time(),"_%Y%m%d"), "backup.csv"))
##datdf <- read.csv("gbif 20191015 backup.csv", stringsAsFactors=FALSE) # to reload a saved search


gbifdata <- datdff_df # just changing the name so it backs up

gbifdata$DataSource <- "GBIF"

names(gbifdata)[names(gbifdata)=='species'] <- 'SNAME'
names(gbifdata)[names(gbifdata)=='key'] <- 'DataID'
names(gbifdata)[names(gbifdata)=='decimalLongitude'] <- 'Longitude'
names(gbifdata)[names(gbifdata)=='decimalLatitude'] <- 'Latitude'
names(gbifdata)[names(gbifdata)=='year'] <- 'LastObs'
names(gbifdata)[names(gbifdata)=='basisOfRecord'] <- 'Notes'

# pull out records with the least uncertainty
gbifdata <- gbifdata[which(gbifdata$coordinateUncertaintyInMeters<=200|is.na(gbifdata$coordinateUncertaintyInMeters)),]

#subset to the needed columns
gbifdata <- gbifdata[c("SNAME","DataID","DataSource","Notes","LastObs","Longitude","Latitude", "coordinateUncertaintyInMeters")]

#remove rows w/ missing data in coordinates
gbifdata <- gbifdata %>% drop_na(Longitude, Latitude)

# use COA
gbifdata$useCOA <- ifelse(gbifdata$LastObs>=cutoffyear, "y", "n")
gbifdata$OccProb <- "k"


gbifdata <- merge(gbifdata, lu_sgcn, by=c('SNAME'), all.x=TRUE)

# delete any bird records because there are so many season issues with them
gbifdata <- gbifdata[which(gbifdata$TaxaGroup!="AB"),]


# create a spatial layer
gbif_sf <- st_as_sf(gbifdata, coords=c("Longitude","Latitude"), crs="+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
gbif_sf <- st_transform(gbif_sf, crs=customalbers) # reproject to the custom albers
gbif_sf <- gbif_sf[final_fields] # field alignment
arc.write(path=here::here("_data","output",updateName,"SGCN.gdb","srcpt_GBIF"), gbif_sf, overwrite=TRUE) # write a feature class into the geodatabase
gbif_buffer_sf <- st_buffer(gbif_sf, dist=100) # buffer by 100m
arc.write(path=here::here("_data","output",updateName,"SGCN.gdb","final_GBIF"), gbif_buffer_sf, overwrite=TRUE) # write a feature class into the geodatabase

